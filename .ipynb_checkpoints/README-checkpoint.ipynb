{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Kinematics Pick & Place\n",
    "\n",
    "The goal of this project is to write code to use pr2 to recognise objects:\n",
    "\n",
    "* Filtering and RANSAC plane fitting implemented.\n",
    "* Clustering for segmentation implemented. \n",
    "* Object recognition implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./images/normal1.png\n",
    "[image2]: ./images/normal2.png\n",
    "[image3]: ./images/normal3.png\n",
    "[image4]: ./images/recognise1.png\n",
    "[image5]: ./images/recognise2.png\n",
    "[image6]: ./images/recognise3.png\n",
    "[image7]: ./images/train1.png\n",
    "[image8]: ./images/train2.png\n",
    "[image9]: ./images/train3.png\n",
    "[image10]: ./images/show.png\n",
    "[image11]: ./images/noise.png\n",
    "\n",
    "---\n",
    "\n",
    "![alt text][image10]\n",
    "\n",
    "### Filtering and RANSAC plane fitting implemented.\n",
    "\n",
    "---\n",
    "* The original point cloud contains a lot of noise as figure below.\n",
    "\n",
    "![alt text][image11]\n",
    "\n",
    "#### step1:   Apply a Voxel Grid Downsampling\n",
    "The code in pr2_robot/scripts/project_template.py between the lines 61-66\n",
    "\n",
    "#### step2:   Apply the Statistical Outlier Removal Filter\n",
    "As for this Filter, i tried many times for better paraments, it appers good \n",
    "when i Set the number of neighboring points to 4 and threshold scale factor to 0.01 to analyze for any given point. Just as the code between the lines\n",
    "67-73.\n",
    "\n",
    "#### step3:   Apply Two PassThrough Filter, one over Z one over X\n",
    "The delailed is lied in the code between the lines 74-89, as for the parameters, you should try many times to find the better one.\n",
    "\n",
    "#### step4:   Apply the RANSAC Plane Segmentation and Extract inliers and outliers\n",
    "The code lies between lines 90-101, as for the parameter max_distance, 0.01 or 0.015 is good.\n",
    "\n",
    "After that we can get point cloud about the table and the objects on the table separately.As the two pictures showed below:\n",
    "\n",
    "pic1:The table point cloud\n",
    "![alt text][image1]\n",
    "\n",
    "\n",
    "pic2:The objects point cloud\n",
    "![alt text][image2]\n",
    "\n",
    "---\n",
    "\n",
    "### Clustering for segmentation implemented.\n",
    "\n",
    "#### step1:   Create Cluster-Mask Point Cloud and Assign a color corresponding to each  segmented object\n",
    "Just as the code between the lines 116-133.\n",
    "\n",
    "#### step2:   Convert PCL data to ROS messages and Publish it\n",
    "Just as the code below:  \n",
    "ros_cluster_cloud = pcl_to_ros(cluster_cloud)  \n",
    "pcl_clusters_pub.publish(ros_cluster_cloud)\n",
    "\n",
    "After that we can get point cloud clustered objects, as the picture showed below:\n",
    "![alt text][image3]\n",
    "\n",
    "---\n",
    "### Object recognition implemented.\n",
    "\n",
    "#### step1:   Extract Features\n",
    "To get better Features data for the SVM to train, i use HSV color channel to compute color histograms. The related code are in captrue_features.py and features.py; Also i modified the for loop in capture_features.py which makes each object is spawned 7 times randomly.\n",
    "\n",
    "#### step2:   Train SVM\n",
    "Use the output features file training_set_x.sav to feed the SVM then you can get the model_x.sav; The main code are in train_svm.py\n",
    "\n",
    "#### step3:   Classify the objects and output the file output_x.yaml \n",
    "The code lies in project_template.py betweens 145-259.\n",
    "* For the test1.world environment, my classifier identify 3/3 objects. As the \n",
    "pictures showed below:\n",
    "![alt text][image7]\n",
    "![alt text][image4]\n",
    "  \n",
    "---\n",
    "* For the test2.world environment, my classifier identify 5/5 objects. As the \n",
    "pictures showed below:\n",
    "![alt text][image8]\n",
    "![alt text][image5]\n",
    "  \n",
    "---\n",
    "* For the test3.world environment, my classifier identify 7/8 objects. As the \n",
    "pictures showed below:\n",
    "![alt text][image9]\n",
    "![alt text][image6]\n",
    "\n",
    "---\n",
    "### Improvement.\n",
    "To better classify the objects, i think i should get more features, maybe 20 training set or more is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
